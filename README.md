# PEtracer 2025

This repository contains the code to reproduce all analyses and figures from the manuscript 
"High-resolution spatial mapping of cell state and lineage dynamics in vivo with PETracer".

![](https://github.com/jweissmanlab/PETracer_Paper/blob/main/img.jpg)
# Setup

### Python environment

```bash
conda env create --file environment.yml
conda activate petracer
ipython kernel install --user --name petracer
```
The [environment.lock.yml](https://github.com/jweissmanlab/PETracer_Paper/tree/main/environment.lock.yml) file can be used to recreate the environment with the exact package versions used in the paper.

### Image processing environment

Image processing was performed on a linux HPC cluster with the following software installed:

* SLURM v23.11.5
* Python v3.11.10
* [Cellpose v3.0.0](https://github.com/MouseLand/cellpose) 
* [Deconwolf v0.4.5](https://elgw.github.io/deconwolf/)
* [Proseg v1.1.3](https://github.com/dcjones/proseg)
* [Fishtank v0.0.1](https://fishtank-jsw.readthedocs.io/en/latest/index.html)
* [MERlin v0.1.8](https://github.com/zhengpuas47/MERlin)
* [MERFISH_probe_design v0.0.1](https://github.com/zhengpuas47/MERFISH_probe_design/releases/tag/v0.0.1)

# Data availability

* Processed data is available on [Figshare](https://figshare.com/s/8e9d573deca3d44235fe)
* Single-cell RNA-seq data is available on [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE290975)
* All other sequencing data is available on [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108)

# Simulation

The [simulation](https://github.com/jweissmanlab/PETracer_Paper/tree/main/simulation) directory 
contains code for simulating lineage tracing data with a variety of parameters. To run simulations:

```bash 
python simulation/simulate.py
```

To generate simulation plots:
```bash
python simulation/plot.py
```
# Prime editing strategy selection

The [insertvariants](https://github.com/jweissmanlab/PETracer_Paper/tree/main/strategy_selection/insertvariants) and [RTT_optimization](https://github.com/jweissmanlab/PETracer_Paper/tree/main/strategy_selection/RTT_optimization) directories 
contain code for processing and analyzing amplicon sequencing data used to select edit sites
and optimize editing strategies for the PEtracer system.

### Data processing

Sequencing data was processed on a Linux HPC cluster with SLURM, Python 3.11, and [CRISPResso 2.2.7](https://github.com/pinellolab/CRISPResso2) installed. Processed files can be generated by running

```bash 
./crispresso.sh
Rscript ../../scripts/make_CRISPResso_summary.R ./ CRISPResso_summary.txt
```

after downloading the fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/strategy_selection/insertvariants/fastq/manifest.txt) from [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108) and placing them in the [strategy_selection/insertvariants/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/strategy_selection/insertvariants/fastq) directory.

### Analysis

**plot.ipynb** - generate strategy selection plots.

# 5nt insert selection

The [insert_selection](https://github.com/jweissmanlab/PETracer_Paper/tree/main/insert_selection) directory 
contains code for processing and analyzing target site sequencing data used to determine the installation 
efficiencies of all 1024 5nt insertions for each edit site.

### Data processing

1. Sequencing data was processed on a Linux HPC cluster with SLURM, Python 3.11, and [CRISPResso 2.2.7](https://github.com/pinellolab/CRISPResso2) installed. Processed files can be generated by running

```bash 
./crispresso.sh
```
after downloading the fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/insert_selection/fastq/manifest.txt)  from [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108) and placing them in the [insert_selection/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/insert_selection/fastq) directory.

2. **aggregate_crispresso.ipynb** - aggregate CRISPResso output files for all sites.
3. **crosshyb.py** - estimate 5nt insert cross-hybridization

### Analysis

To generate insert selection plots:
```bash
python insert_selection/plot.py
```

# Insert validation

The [insert_validation](https://github.com/jweissmanlab/PETracer_Paper/tree/main/insert_validation) directory 
contains code for processing and analyzing amplicon sequencing data used for arrayed validation of the top 5nt insertions
for each edit site.

### Data processing

Sequencing data was processed on a Linux HPC cluster with SLURM, Python 3.11, and [CRISPResso 2.2.7](https://github.com/pinellolab/CRISPResso2) installed. Processed files can be generated by running

```bash 
./crispresso.sh
Rscript ../scripts/make_CRISPResso_summary.R ./ CRISPResso_summary.txt
```

after downloading the fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/insert_validation/fastq/manifest.txt) from [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108) and placing them in the [insert_validation/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/insert_validation/fastq) directory.

### Analysis

**plot.ipynb** - generate arrayed validation plots for top 5nt insertions.

# Orthogonalization

The [orthogonalization](https://github.com/jweissmanlab/PETracer_Paper/tree/main/orthogonalization) directory 
contains code for processing and analyzing amplicon sequencing data used for validating orthogonalized versions
of the RNF2, HEK3, and EMX1 edit sites.

### Data processing

Sequencing data was processed on a Linux HPC cluster with SLURM, Python 3.11, and [CRISPResso 2.2.7](https://github.com/pinellolab/CRISPResso2) installed. Processed files can be generated by running

```bash 
./crispresso.sh
Rscript ../scripts/make_CRISPResso_summary.R ./ CRISPResso_summary.txt
```

after downloading the fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/orthogonalization/fastq/manifest.txt) from [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108) and placing them in the [orthogonalization/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/orthogonalization/fastq) directory.

### Analysis

**plot.ipynb** - generate orthogonalization plots.

# Orthogonal insert validation

The [orthogonal_insert_validation](https://github.com/jweissmanlab/PETracer_Paper/tree/main/orthogonal_insert_validation) directory 
contains code for processing and analyzing amplicon sequencing data used for validating the top 20 5nt insertions at each orthogonalized edit site.

### Data processing

Sequencing data was processed on a Linux HPC cluster with SLURM, Python 3.11, and [CRISPResso 2.2.7](https://github.com/pinellolab/CRISPResso2) installed. Processed files can be generated by running

```bash 
./crispresso.sh
Rscript ../scripts/make_CRISPResso_summary.R ./ CRISPResso_summary.txt
```

after downloading the fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/orthogonal_insert_validation/fastq/manifest.txt) from [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108) and placing them in the [orthogonal_insert_validation/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/orthogonal_insert_validation/fastq) directory.

### Analysis

**plot.ipynb** - generate plots for top 20 5nt insertions.

# pegArray balance

The [peg_arrays](https://github.com/jweissmanlab/PETracer_Paper/tree/main/peg_arrays) directory 
contains code for processing and analyzing target site sequencing data used to determine the LM installation 
balance for various pegArrays.

### Data processing

Sequencing data was processed on a Linux HPC cluster with SLURM, Python 3.11, and [CRISPResso 2.2.7](https://github.com/pinellolab/CRISPResso2) installed. Processed files can be generated by running

```bash 
sbatch peg_arrays/crispresso.slurm
python peg_arrays/count_alleles.py
```

after downloading the fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/peg_arrays/fastq/manifest.txt) from [SRA](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1231108) and placing them in the [peg_arrays/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/peg_arrays/fastq) directory.

### Analysis

To generate pegArray plots:
```bash
python peg_arrays/plot.py
```

# pegRNA variant kinetics

The [kinetics](https://github.com/jweissmanlab/PETracer_Paper/tree/main/kinetics) directory 
contains code for processing and analyzing 10x data for 4T1 and B16 cells transduced with a library
of pegRNA variants to test editing kinetics.

### Data processing

10x data was processed on a Linux HPC cluster with SLURM, Python 3.11, and Cellranger 7.1.0 installed.
Processed files can be generated with the following steps:

1. Run Cellranger and call alleles using bam files.
```bash 
sbatch kinetics/cellranger.slurm
sbatch kinetics/call_alleles.slurm
```
2. **process_4T1_10x.ipynb** - perform quality control, call pegRNA variants, and determine edit fraction for 4T1 cells.
3. **process_B16F10_10x.ipynb** - perform quality control, call pegRNA variants, and determine edit fraction for B16F10 cells.


after downloading the 10x fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/kinetics/fastq/manifest.txt) from [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE290975) and placing them in the [kinetics/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/kinetics/fastq) directory.

### Analysis

All kinetics analysis and plots can be generated by running
```bash
python kinetics/estimate_rate.py
python kinetics/plot.py
```
after processing the raw data or downloading the processed files from [Figshare](https://figshare.com/s/8e9d573deca3d44235fe) and placing them in [kinetics/data](https://github.com/jweissmanlab/PETracer_Paper/tree/main/kinetics/data) directory:

* 4T1_kinetics_alleles.csv
* 4T1_kinetics_cells.csv
* 4T1_kinetics.h5ad
* B16F10_kinetics_alleles.csv
* B16F10_kinetics_cells.csv
* B16F10_kinetics.h5ad

# Integration barcode design

Detailed integration barcode design jupyter notebooks are in folder *design_intBC*. 

# Probe design

Detailed MERFISH and PEtracer probe design are in folder *design_probes*. This part requires installation of package: [MERFISH_probe_design](https://github.com/zhengpuas47/MERFISH_probe_design/releases/tag/v0.0.1)


# Image processing

The [image_processing](https://github.com/jweissmanlab/PETracer_Paper/tree/main/image_processing) directory 
contains code for processing imaging data. Raw imaging files are not publicly available due to file size, but code can be used to process other imaging data in the same format. Processed files for each experiment (e.g. 241213_F320-4-3_MF4++) can be generated with the following steps:

1. Nuclei segmentation using Cellpose and Deconwolf
```bash
sbatch image_processing/241213_F320-4-3_MF4++/Scripts/cellpose.slurm
```
2. MERFISH transcript decoding using Merlin

> Download the newest version of MERLin here: [Link to MERLin release](https://github.com/zhengpuas47/MERlin/releases/tag/v0.1.8)
>> install the merlin by:
>> ```bash
>> conda create -n merlin_py310 python=3.10
>> conda activate merlin_py310
>> conda install h5py rtree pytables setuptools urllib3 python-dotenv pandas tifffile
>> conda install scikit-image scikit-learn scipy matplotlib networkx seaborn
>> conda install pytest pytest-cov numexpr cython requests boto3 xmltodict google-cloud-storage docutils pillow
>> pip install opencv-python pyqt5 sphinx-rtd-theme snakemake pyclustering tables cellpose
>> pip install -e MERLin
>>```
>> Test if the installation works by:
>> ```bash
>> merlin -h
>> ```
>> For the first time using MERLin, configure it by:
>> ```bash
>> merlin --configure .
>> ```
>> Then follow the instruction. 
>
> Run MERLin:
>> Example command:
>> ```bash
>> merlin -a 20241007-MF4_TestPreprocess.json \
>> 		-o 20240812-MF4_16bit.csv \
>> 		-c MF4dna_codebook.csv \
>> 		-m merscope01_microscope.json \
>> 		-p 20240812_positions.txt \
>> 		-e /lab/weissman_imaging/puzheng/4T1Tumor \
>> 		-s /lab/weissman_imaging/puzheng/MERFISH_analysis/4T1 \
>> 		-k run_MF4_cellpose.json \
>> 		-n 2 \
>> 		--no_report True \
>> 		20240812-F319-12-0807_MF4dna-mCh
>> ```
>> The example parameter files are provided in folder: *merlin_parameters*. Make sure to keep the subfolder structures and set the PARAMETER_HOME in the configuration step as the absolute path of this merlin_parameters folder.

3. Assignment of cytoplasmic transcripts to nuclei using Proseg
```bash
sbatch image_processing/241213_F320-4-3_MF4++/Scripts/proseg.slurm
```
4. Alignment of MERFISH and lineage imaging data using fishtank
```bash
sbatch image_processing/241213_F320-4-3_MF4++/Scripts/align_experiments.slurm
```
5. T7 amplicon detection and quantification using fishtank
```bash
sbatch image_processing/241213_F320-4-3_MF4++/Scripts/detect_spots.slurm
```
6. T7 amplicon decoding and cell assignment using fishtank
```bash
sbatch image_processing/241213_F320-4-3_MF4++/Scripts/decode_spots.slurm
```

This process was repeated for each imaging experiment, except for experiments without MERFISH data, which only required steps 1, 5, and 6.

# Predefined lineage mark validation

The [preedited](https://github.com/jweissmanlab/PETracer_Paper/tree/main/preedited) directory 
contains code for processing and analyzing 10x and imaging-based readout of lineage tracing data
from cells with predefined linkage between intBCs and lineage marks.

### Data processing

Imaging data was processed as described in the "Image processing" section. 10x data was processed on 
a Linux HPC cluster with SLURM, Python 3.11, and Cellranger 7.1.0 installed.
Processed files can be generated with the following steps:

1. For 10x run Cellranger and call alleles using bam files.
```bash 
sbatch preedited/cellranger.slurm
sbatch preedited/call_alleles.slurm
```
2. **process_10x_invitro.ipynb** - perform quality control for 10x in vitro data.
3. **process_merfish_invitro.ipynb** - perform quality control for imaging in vitro data.
4. **process_merfish_zombie.ipynb** - perform quality control for imaging in vitro data using the zombie protocol.
5. **process_merfish_invivio.ipynb** - perform quality control for imaging in vivo data.

after downloading the 10x fastq files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/preedited/fastq/manifest.txt) from [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE290975) and placing them in the [preedited/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/preedited/fastq) directory.

### Analysis

All preedited analysis and plots can be generated by running
```bash
python preedited/plot.py
```
after processing the raw data or downloading the processed files from [Figshare](https://figshare.com/s/8e9d573deca3d44235fe) and placing them in [peedited/data](https://github.com/jweissmanlab/PETracer_Paper/tree/main/colony_tracing/data) directory:

* preedited_10x_invitro_alleles.csv
* preedited_10x_invitro.h5ad
* preedited_merfish_invitro_alleles.csv
* preedited_merfish_invitro_cells.json
* preedited_merfish_invivo_alleles.csv
* preedited_merfish_invivo_cells.json
* preedited_merfish_zombie_alleles.csv
* preedited_merfish_zombie_cells.json

# Barcoded lineage tracing

The [barcoded_tracing](https://github.com/jweissmanlab/PETracer_Paper/tree/main/barcoded_tracing) directory 
contains code for processing and analyzing 10x single-cell lineage tracing for clones with puro and blast-linked
static barcodes serving as independent validation of phylogenetic relationships.

### Data processing

Data processing was performed on a Linux HPC cluster with SLURM, Python 3.11, and Cellranger 7.1.0 installed.
Processed files can be generated with the following steps:

1. Run Cellranger and call alleles using bam files.
```bash 
sbatch barcoded_tracing/cellranger.slurm
sbatch barcoded_tracing/call_alleles.slurm
```
2. **process_10x.ipynb** - performs quality control, phylogenetic reconstruction, and processing of barcode data.

after downloading the files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/barcoded_tracing/fastq/manifest.txt) from [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE290975) and placing them in the [barcoded_tracing/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/barcoded_tracing/fastq) directory.

### Analysis

All barcoded tracing analysis and plots can be generated by running
```bash
python barcoded_tracing/evaluate.py
python barcoded_tracing/plot.py
```
after processing the raw data or downloading the processed files from [Figshare](https://figshare.com/s/8e9d573deca3d44235fe) and placing them in [colony_tracing/data](https://github.com/jweissmanlab/PETracer_Paper/tree/main/colony_tracing/data) directory:

* barcoded_tracing_clone_1.h5td
* barcoded_tracing_clone_2.h5td
* barcoded_tracing_clone_3.h5td
* barcoded_tracing_clone_4.h5td
* barcoded_tracing_clone_5.h5td
* barcoded_tracing_clone_6.h5td
* barcoded_tracing_alleles.csv

# Colony lineage tracing

The [colony_tracing](https://github.com/jweissmanlab/PETracer_Paper/tree/main/colony_tracing) directory 
contains code for processing and analyzing single-cell lineage tracing from colonies generated by 
sparsely seeding 4T1 cells onto a coverslip.

### Data processing

After processing raw images as described in the "Image processing" section the **colony_process_lineage.ipynb** 
notebook was used to segment colonies, perform quality control, and reconstruct phylogenies.

### Analysis

All colony plots can be generated by running
```bash
python colony_tracing/plot.py
```
after the following files from [Figshare](https://figshare.com/s/8e9d573deca3d44235fe) are downloaded 
and placed in the [colony_tracing/data](https://github.com/jweissmanlab/PETracer_Paper/tree/main/colony_tracing/data) directory:

* colony_tracing.h5td
* colony_polygons.json

# 4T1 in vitro heterogeneity
The [invitro_heterogeneity](https://github.com/jweissmanlab/PETracer_Paper/tree/main/invitro_heterogeneity) directory contains code for processing and analyzing single-cell data characterizing in vitro transcriptional heterogeneity in engineered 4T1 cells used to seed tumors.

### Data processing

Data processing was performed on a Linux HPC cluster with SLURM, Python 3.11, and Cellranger 7.1.0 installed.
Processed files can be generated with the following steps:

1. Run Cellranger and call alleles using bam files.
```bash 
sbatch invitro_heterogeneity/cellranger.slurm
sbatch invitro_heterogeneity/call_alleles.slurm
```
2. **process_10x.ipynb** - performs quality control and clustering.

after downloading the files listed in [manifest.txt](https://github.com/jweissmanlab/PETracer_Paper/tree/main/invitro_heterogeneity/fastq/manifest.txt) from [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE290975) and placing them in the [invitro_heterogeneity/fastq](https://github.com/jweissmanlab/PETracer_Paper/tree/main/invitro_heterogeneity/fastq) directory.

### Analysis

All in vitro heterogeneity analysis and plots can be generated by running
```bash
python invitro_heterogeneity/plot.py
```
after processing the raw data or downloading the processed files from [Figshare](https://figshare.com/s/8e9d573deca3d44235fe) and placing them in [invitro_heterogeneity/data](https://github.com/jweissmanlab/PETracer_Paper/tree/main/invitro_heterogeneity/data) directory:

* 4T1_invitro.h5ad

# 4T1 tumor lineage tracing

The [tumor_tracing](https://github.com/jweissmanlab/PETracer_Paper/tree/main/tumor_tracing) directory 
contains code for processing and analyzing single-cell transcriptomic and lineage tracing data 
from the 4T1 syngeneic mouse model of tumor metastasis.

### Data processing

After processing raw images as described in the "Image processing" section, the following notebooks were used to generate the mouse 1 data:

1. **M1_resolVI_training.ipynb** - trains resolVI model to classify cell types and filter out doublets.
2. **M1_process_MERFISH.ipynb** - performs quality control and annotation of the MERFISH data.
3. **M1_segment_tumors.ipynb** - aligns tumor sections, segments tumors, and calculate spatial statistics.
4. **M1_process_lineage.ipynb** - performs quality control of lineage data and reconstructs phylogenies.

The same process was repeated for the mouse 2 and 3 data, except a new resolVI model was not trained for mouse 2 since the library is shared with mouse 1.

### Analysis

All tumor plots can be generated by running
```bash
python tumor_tracing/plot.py
```
after the following files from [Figshare](https://figshare.com/s/8e9d573deca3d44235fe) are downloaded 
and placed in the [tumor_tracing/data](https://github.com/jweissmanlab/PETracer_Paper/tree/main/tumor_tracing/data) directory:

* 10x_4T1_primary.h5ad
* M1_tumor_tracing.h5td
* M1_polygons_grid.json
* M2_tumor_tracing.h5td
* M2_polygons.json
* M3_tumor_tracing.h5td
* M3_polygons_grid.json
